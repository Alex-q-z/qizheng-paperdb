# Large Language Models

## Inference-Time Scaling

Can we leverage inference-time compute scaling techniques, like best-of-n sampling or self-refinement, to achieve better model performance?

* Large Language Monkeys: Scaling Inference Compute with Repeated Sampling, arXiv:2407.21787v2 [[paper]](https://arxiv.org/abs/2407.21787)

## Speculative Decoding

Accelerating large-model inference with speculative sampling from a small-model. A more comprehensive survey github repo is [[here]](https://github.com/hemingkx/SpeculativeDecodingPapers).

* Fast Inference from Transformers via Speculative Decoding, ICML 2023 oral [[paper]](https://arxiv.org/abs/2211.17192)
* Accelerating Large Language Model Decoding with Speculative Sampling, arXiv:2302.01318v1 [[paper]](https://arxiv.org/pdf/2302.01318)
* SpecInfer: Accelerating Generative LLM Serving with Speculative Inference and Token Tree Verification, ASPLOS 2024 [[paper]](https://arxiv.org/abs/2305.09781)
* REST: Retrieval-Based Speculative Decoding, NAACL 2024 [[paper]](https://arxiv.org/pdf/2311.08252)
* DistillSpec: Improving Speculative Decoding via Knowledge Distillation, ICLR 2024 [[paper]](https://arxiv.org/pdf/2310.08461)
* Online Speculative Decoding, ICML 2024 [[paper]](https://arxiv.org/abs/2310.07177)
* Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads, ICML 2024 [[paper]](https://arxiv.org/abs/2401.10774)
* Sequoia: Scalable, Robust, and Hardware-aware Speculative Decoding, arXiv:2402.12374v2 [[paper]](https://arxiv.org/pdf/2402.12374)

## LLMs + Programming

Improving LLM capabilities through generating intermediate computer programs.

* PAL: Program-aided Language Models [[paper]](https://arxiv.org/abs/2211.10435)
* The ALCHEmist: Automated Labeling 500x CHEaper Than LLM Data Annotators, NeurIPS 2024 [[paper]](https://arxiv.org/abs/2407.11004)

## Compound AI Systems: Optimization

Design and optimization of AI systems where more than one LLM is used.

* TextGrad: Automatic "Differentiation" via Text, arXiv:2406.07496v1 [[paper]](https://arxiv.org/pdf/2406.07496)

## Compound AI Systems: Programming

* DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines, ICLR 2024 spotlight [[paper]](https://arxiv.org/abs/2310.03714)

## Weak Supervision

* Your Weak LLM is Secretly a Strong Teacher for Alignment, arXiv:2409.08813v1 [[paper]](https://arxiv.org/pdf/2409.08813)
